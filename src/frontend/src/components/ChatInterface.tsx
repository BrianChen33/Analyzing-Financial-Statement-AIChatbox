import { useState, useEffect, useRef } from 'react'
import {
  Box,
  Paper,
  TextField,
  IconButton,
  Typography,
  Avatar,
  List,
  ListItem,
  ListItemAvatar,
  ListItemText,
  Divider,
  CircularProgress,
  Tooltip,
  Button
} from '@mui/material'
import { Send, Person, SmartToy, Mic, VolumeUp, Stop } from '@mui/icons-material'
import api from '@/services/api'
import ReactMarkdown from 'react-markdown'

interface ChatInterfaceProps {
  analysisData: any
}

interface Message {
  role: 'user' | 'assistant'
  content: string
}

export default function ChatInterface({ analysisData }: ChatInterfaceProps) {
  const [messages, setMessages] = useState<Message[]>([
    {
      role: 'assistant',
      content: 'Hello! I\'m your financial analysis assistant. Ask me anything about the analyzed financial statement.'
    }
  ])
  const [input, setInput] = useState('')
  const [loading, setLoading] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const synthesisRef = useRef<SpeechSynthesis | null>(null)

  const handleSend = async () => {
    if (!input.trim()) return

    const userMessage: Message = { role: 'user', content: input }
    setMessages(prev => [...prev, userMessage])
    setInput('')
    setLoading(true)

    try {
      const response = await api.chat({
        question: input,
        context: analysisData
      })

      const assistantMessage: Message = {
        role: 'assistant',
        content: response.answer
      }
      setMessages(prev => [...prev, assistantMessage])
    } catch (error: any) {
      const errorMessage: Message = {
        role: 'assistant',
        content: error.message || 'Sorry, I encountered an error. Please try again.'
      }
      setMessages(prev => [...prev, errorMessage])
    } finally {
      setLoading(false)
    }
  }

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault()
      handleSend()
    }
  }

  // ÂàùÂßãÂåñËØ≠Èü≥ËØÜÂà´
  useEffect(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = window.SpeechRecognition || (window as any).webkitSpeechRecognition
      
      if (SpeechRecognition) {
        const recognition = new SpeechRecognition()
        recognition.continuous = false
        recognition.interimResults = false
        recognition.lang = 'en-US'
        
        recognition.onstart = () => {
          setIsRecording(true)
        }
        
        recognition.onresult = (event: SpeechRecognitionEvent) => {
          const transcript = event.results[0][0].transcript
          setInput(prev => prev + (prev ? ' ' : '') + transcript)
          setIsRecording(false)
        }
        
        recognition.onerror = (event: any) => {
          console.error('Speech recognition error:', event.error)
          setIsRecording(false)
          
          let errorMessage = 'ËØ≠Èü≥ËØÜÂà´ÈîôËØØ: '
          switch (event.error) {
            case 'not-allowed':
              errorMessage = 'È∫¶ÂÖãÈ£éÊùÉÈôêË¢´ÊãíÁªù„ÄÇËØ∑Âú®ÊµèËßàÂô®ËÆæÁΩÆ‰∏≠ÂÖÅËÆ∏È∫¶ÂÖãÈ£éÊùÉÈôê„ÄÇ'
              break
            case 'network':
              errorMessage = 'ÁΩëÁªúËøûÊé•ÈîôËØØ„ÄÇWeb Speech APIÈúÄË¶ÅÁΩëÁªúËøûÊé•ÊâçËÉΩÂ∑•‰Ωú„ÄÇ\n\nËß£ÂÜ≥ÊñπÊ°àÔºö\n1. Ê£ÄÊü•ÁΩëÁªúËøûÊé•\n2. Á°Æ‰øùÂèØ‰ª•ËÆøÈóÆGoogleÊúçÂä°ÔºàËØ≠Èü≥ËØÜÂà´‰ΩøÁî®GoogleÊúçÂä°Ôºâ\n3. Â¶ÇÊûúÂú®‰∏≠ÂõΩÔºåÂèØËÉΩÈúÄË¶ÅVPNÊàñ‰ΩøÁî®ÂÖ∂‰ªñËØ≠Èü≥ËæìÂÖ•ÊñπÂºè'
              break
            case 'no-speech':
              errorMessage = 'Êú™Ê£ÄÊµãÂà∞ËØ≠Èü≥„ÄÇËØ∑Á°Æ‰øùÈ∫¶ÂÖãÈ£éÊ≠£Â∏∏Â∑•‰ΩúÂπ∂Ê∏ÖÊô∞ËØ¥ËØù„ÄÇ'
              break
            case 'audio-capture':
              errorMessage = 'Êó†Ê≥ïÊçïËé∑Èü≥È¢ë„ÄÇËØ∑Ê£ÄÊü•È∫¶ÂÖãÈ£éÊòØÂê¶Ê≠£Â∏∏Â∑•‰Ωú„ÄÇ'
              break
            case 'aborted':
              errorMessage = 'ËØ≠Èü≥ËØÜÂà´Ë¢´‰∏≠Ê≠¢„ÄÇ'
              break
            default:
              errorMessage = `ËØ≠Èü≥ËØÜÂà´ÈîôËØØ: ${event.error}`
          }
          
          alert(errorMessage)
        }
        
        recognition.onend = () => {
          setIsRecording(false)
        }
        
        recognitionRef.current = recognition
      }
      
      if ('speechSynthesis' in window) {
        synthesisRef.current = window.speechSynthesis
      }
    }
    
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop()
      }
      if (synthesisRef.current) {
        synthesisRef.current.cancel()
      }
    }
  }, [])

  const handleVoiceInput = () => {
    if (!recognitionRef.current) {
      alert('Speech recognition is not supported in your browser. Please use Chrome or Edge.')
      return
    }
    
    if (isRecording) {
      recognitionRef.current.stop()
      setIsRecording(false)
    } else {
      // Ê£ÄÊü•ÁΩëÁªúËøûÊé•
      if (!navigator.onLine) {
        alert('ÁΩëÁªúËøûÊé•‰∏çÂèØÁî®„ÄÇËØ≠Èü≥ËØÜÂà´ÈúÄË¶ÅÁΩëÁªúËøûÊé•„ÄÇËØ∑Ê£ÄÊü•ÁΩëÁªúÂêéÈáçËØï„ÄÇ')
        return
      }
      
      try {
        recognitionRef.current.start()
      } catch (error: any) {
        console.error('Failed to start recognition:', error)
        setIsRecording(false)
        
        // Êèê‰æõÊõ¥ÂèãÂ•ΩÁöÑÈîôËØØÊèêÁ§∫
        if (error.message && error.message.includes('network')) {
          alert('ÁΩëÁªúËøûÊé•ÈîôËØØ„ÄÇ\n\nËØ≠Èü≥ËØÜÂà´ÈúÄË¶ÅÁΩëÁªúËøûÊé•ÊâçËÉΩÂ∑•‰Ωú„ÄÇ\n\nÂ¶ÇÊûúÊåÅÁª≠Âá∫Áé∞Ê≠§ÈîôËØØÔºåËØ∑Ôºö\n1. Ê£ÄÊü•ÁΩëÁªúËøûÊé•\n2. Á°Æ‰øùÂèØ‰ª•ËÆøÈóÆGoogleÊúçÂä°\n3. Êàñ‰ΩøÁî®ÊâãÂä®ËæìÂÖ•‰ª£ÊõøËØ≠Èü≥ËæìÂÖ•')
        } else {
          alert(`ÂêØÂä®ËØ≠Èü≥ËØÜÂà´Â§±Ë¥•: ${error.message || 'Êú™Áü•ÈîôËØØ'}\n\nËØ∑Â∞ùËØïÊâãÂä®ËæìÂÖ•ÈóÆÈ¢ò„ÄÇ`)
        }
      }
    }
  }

  const handleSpeak = (text: string) => {
    if (!synthesisRef.current) {
      return
    }
    
    // ÂÅúÊ≠¢ÂΩìÂâçÊí≠Êîæ
    synthesisRef.current.cancel()
    
    // ÊèêÂèñÁ∫ØÊñáÊú¨ÔºàÂéªÈô§markdownÊ†ºÂºèÔºâ
    const plainText = text.replace(/[#*`_~\[\]()]/g, '').replace(/\n/g, ' ')
    
    const utterance = new SpeechSynthesisUtterance(plainText)
    utterance.lang = 'en-US'
    utterance.rate = 0.9
    utterance.pitch = 1.0
    utterance.volume = 1.0
    
    utterance.onstart = () => {
      setIsSpeaking(true)
    }
    
    utterance.onend = () => {
      setIsSpeaking(false)
    }
    
    utterance.onerror = (event) => {
      console.error('Speech synthesis error:', event)
      setIsSpeaking(false)
    }
    
    synthesisRef.current.speak(utterance)
  }

  const stopSpeaking = () => {
    if (synthesisRef.current) {
      synthesisRef.current.cancel()
      setIsSpeaking(false)
    }
  }

  return (
    <Box sx={{ height: '70vh', display: 'flex', flexDirection: 'column' }}>
      <Paper sx={{ flexGrow: 1, overflow: 'auto', p: 2, mb: 2 }}>
        <List>
          {messages.map((message, index) => (
            <Box key={index}>
              <ListItem alignItems="flex-start">
                <ListItemAvatar>
                  <Avatar sx={{ bgcolor: message.role === 'user' ? 'primary.main' : 'secondary.main' }}>
                    {message.role === 'user' ? <Person /> : <SmartToy />}
                  </Avatar>
                </ListItemAvatar>
                <ListItemText
                  primary={
                    <Typography variant="subtitle2">
                      {message.role === 'user' ? 'You' : 'AI Assistant'}
                    </Typography>
                  }
                  secondary={
                    <Box sx={{ mt: 1 }}>
                      {message.role === 'assistant' ? (
                        <>
                          <ReactMarkdown>{message.content}</ReactMarkdown>
                          <Tooltip title={isSpeaking ? "Stop speaking" : "Read aloud"}>
                            <IconButton 
                              size="small" 
                              onClick={() => isSpeaking ? stopSpeaking() : handleSpeak(message.content)}
                              sx={{ mt: 1 }}
                              color={isSpeaking ? "error" : "default"}
                            >
                              {isSpeaking ? <Stop fontSize="small" /> : <VolumeUp fontSize="small" />}
                            </IconButton>
                          </Tooltip>
                        </>
                      ) : (
                        <Typography variant="body2">{message.content}</Typography>
                      )}
                    </Box>
                  }
                />
              </ListItem>
              {index < messages.length - 1 && <Divider />}
            </Box>
          ))}
          {loading && (
            <ListItem>
              <ListItemAvatar>
                <Avatar sx={{ bgcolor: 'secondary.main' }}>
                  <SmartToy />
                </Avatar>
              </ListItemAvatar>
              <ListItemText
                primary="AI Assistant"
                secondary={<CircularProgress size={20} />}
              />
            </ListItem>
          )}
        </List>
      </Paper>

      <Paper sx={{ p: 2 }}>
        <Box sx={{ display: 'flex', gap: 1, alignItems: 'flex-end' }}>
          <Tooltip title={isRecording ? "Stop recording" : "Voice input (ÈúÄË¶ÅÁΩëÁªúËøûÊé•)"}>
            <IconButton 
              color={isRecording ? 'error' : 'default'}
              onClick={handleVoiceInput}
              disabled={loading}
            >
              {isRecording ? <Stop /> : <Mic />}
            </IconButton>
          </Tooltip>
          <TextField
            fullWidth
            multiline
            maxRows={4}
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder={isRecording ? "Listening..." : "Ask a question about the financial statement... (ÊàñÁÇπÂáªüé§‰ΩøÁî®ËØ≠Èü≥ËæìÂÖ•)"}
            disabled={loading || isRecording}
            helperText={isRecording ? "Speak your question..." : "ÊèêÁ§∫ÔºöÂ¶ÇÊûúËØ≠Èü≥ËæìÂÖ•Êó†Ê≥ï‰ΩøÁî®ÔºåËØ∑Áõ¥Êé•ÊâãÂä®ËæìÂÖ•ÈóÆÈ¢ò"}
          />
          <IconButton 
            color="primary" 
            onClick={handleSend}
            disabled={loading || !input.trim() || isRecording}
          >
            <Send />
          </IconButton>
        </Box>
        {/* Â∏∏Áî®ÈóÆÈ¢òÂø´Êç∑ÊåâÈíÆ */}
        <Box sx={{ mt: 2, display: 'flex', gap: 1, flexWrap: 'wrap' }}>
          <Typography variant="caption" sx={{ width: '100%', mb: 0.5 }}>
            Â∏∏Áî®ÈóÆÈ¢òÔºö
          </Typography>
          {[
            "What is the profit margin?",
            "Tell me about the revenue",
            "What are the risks?",
            "How is the liquidity?"
          ].map((q, idx) => (
            <Button
              key={idx}
              size="small"
              variant="outlined"
              onClick={() => setInput(q)}
              disabled={loading || isRecording}
              sx={{ fontSize: '0.75rem' }}
            >
              {q}
            </Button>
          ))}
        </Box>
      </Paper>
    </Box>
  )
}
